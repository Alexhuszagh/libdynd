Dynamic ND-Array Library Design
-------------------------------

This is a library that I (Mark Wiebe) am developing in a proprietary
fashion, within the spirit of NumPy, but designed to be comfortable
in C++. It's main goals are:

* Have a flexible and high-performance data type mechanism, which can
  be extended to have new data types with POD or object semantics.
* A simple strided memory layout like NumPy, with KEEPORDER semantics
  by default.
* A design that's flexible enough to allow the data to be stored
  in CPU memory, GPU memory, or distributed across a cluster in a global
  array.
* Delayed execution by default - all operations return views or
  arrays with their computation deferred.
* Include a compiler technology to take the deferred expression trees
  and create optimized execution plans. Either directly executing the
  expression tree, creating a compact block-based execution engine along
  the lines of numexpr, or JITting with LLVM.

Some principles which seem desirable:

1. Everything is a view. Array operations do not compute an answer,
   they merely compute the new dtype, geometry, and an expression tree.
   Since this is based on reference counting, using the library to
   implement copy-on-write semantics is possible as well.
2. There is no default "flat" perspective, any conversion between
   multi-dimensional and one-dimensional is explicit.
3. Default type conversion follows strict value-preserving semantics,
   except double -> float conversions in the precision-loss case.
4. Default overflow checking for integer math. This appears to require
   assembly-language implementations of inner loops, and precludes the
   use of SSE operations, as they set no overflow/carry flags when doing
   integer operations.

Some performance-oriented design features:

1. The dtype has all the basic necessary information in a pass-by-value
   class. For dtypes that require extended information, like structs,
   a virtual base class with additional information is added as well,
   and is reference counted which works because the extended info is
   treated as an immutable object once created.
2. The ndarray always exposes arrays that are aligned and in NBO. The only
   way to see a non-NBO array is to dig into the expression tree itself,
   behind the veil of buffering.
3. Computations have inner loop functions that can be specialized based on
   the striding of the data in that inner loop. Important special cases
   are constant strides and strides equal to the dtype itemsize. I've confirmed
   that g++ 4.6.1 creates SSE based inner loops for the contiguous versions
   of the arithmetic operations.

Everything Is A View
--------------------

In NumPy, some operations return views, and others return copies. In
this library, the idea is that everything is a view, either directly via
a linear striding operation, or indirectly via an expression tree.
Leaf nodes of the expression trees can either be ndarrays themselves,
or rvalue array generators, such as a constant generator or a linear range
generator.

This design choice is analogous to the shift towards using iterators
for most things in Python 3. For example, in Python 2, range(4) returns
a list [0, 1, 2, 3], whereas in Python 3 it returns a generator object
whose repr is 'range(0, 4)'.

Every operation in the system produces a view of the inputs. Suppose we
have two arrays, 'a' and 'b'. If we assign 'c = a + b', 'c' is now a view
into the sum of 'a' and 'b'. Note that 'c' itself is now an rvalue array, as
there are multiple ways an assigned value could be split up between 'a' and
'b', so such an assignment is not unique. If we take a value of 'c', for
example 'c(0,0).as<float>()', then modify 'a(0,0)', taking that value of 'c'
again will be different. The view nature of this can be collapsed by running
'c.as_lvalue()' (function subject to renaming).

Some example ndarray_expr_node subclasses:

zero_gen<dtype>, one_gen<dtype>, constant_gen<dtype, value> (rvalue):
    Generates 0, 1 or arbitrary constant values, respectively.

int_range<integer dtype, origin, step[ndim], shape[ndim]> (rvalue):
    Generates an integer range. This structure can be preserved under
    remapping to multi-dimensional data and linear indexing.

constant_multiply<dtype, A, childnode> (maybe lvalue?):
    Maps the input value x to A * x.

constant_add<dtype, A, childnode> (maybe lvalue?):
    Maps the input value x to A + x.

multiply<dtype, childnode0, childnode1> (rvalue):
    Maps the input value x, y to x * y. Similar versions of add, subtract,
    divide, etc. The childnodes must have identical shapes.

linear_map<float/complex dtype, A, B, childnode> (maybe lvalue?):
    Maps the input value x to A*x + B. A linspace is an int_range followed by
    a linear_map. If A is non-zero, this is invertible, and we could
    treat this as an lvalue array. Whether this in general is desireable needs
    some thought.

broadcast_shape<ndim, shape[ndim], axismap[childnode.ndim], childnode>
    Broadcasts the childnode to the specified shape, according to the specified
    mapping of the axes. These nodes are added when necessary for multiply-type
    nodes.

flat_to_ndim<ndim, shape[ndim], strides[ndim], childnode> (lvalue):
    Maps a one-dimensional array to a multi-dimensional array.
    result[i[0], ..., i[ndim-1]] ==
    childnode[strides[0]*i[0] + ... + strides[ndim-1]*i[ndim-1]].

linear_index<ndim, shape[ndim], base[ndim], strides[ndim], childnode> (lvalue):
    Does a linear strided indexing operation into the childnode. This doesn't
    change the number of dimensions of the childnode.

To heuristically determine where to create temporaries, the nodes should indicate
an estimate of how many source node accesses are required for each result
element. For example, a matrix multiply node for an m by n times an n by r matrix,
would indicate 2*n for each output element.

Reference Assignment vs Value Assignment
----------------------------------------

This library has two types of assignment operations, assigning by
reference and assigning by value. This is similar to NumPy, where
this distinction can trip up programmers fairly easily:

    a = np.arange(10)
    for x in np.nditer(a):
        # Oops! Wanted value assignment, not reference assignment
        x = np.sin(x)
        # Should have been this:
        x[...] = np.sin(x)

In a C++ library, assignment is usually done by value, and the language
has lvalue and rvalue references built in. The ndarray object references
data in a buffer, however, which means a C++ assignment of an ndarray
could either copy values into its buffer, or turn the destination object
into a reference pointing at the array being assigned. User code needs the
ability to do both of these operations.

My initial design choice was to make operator= be reference assignment, and
write a function called vassign for value assignment. This can lead to a
big surprise as follows:

    ndarray a = arange(10).as_strided();
    // Oops! Wanted value assignment, not reference assignment
    // This turns into a NOP, because a(3) produces a temporary ndarray,
    // which becomes a reference to an array containing the value 2, then
    // gets destroyed. The programmer gets no signal that this happens!
    a(3) = 2;
    // Should have been this:
    a(3).vassign(2);

To retain programmer sanity, the above should produce an error, an
exception, or should be a value assignment. I haven't been able to think
of a good way to detect this case, as a(3) must return a non-const reference,
the value 2 is convertible to an ndarray. This assignment works fine as far
as the compiler is concerned. A difference with Python is that in python,
"a[3] = 2" is a different operation than "a = 2", but here in C++, they are
identical.

On the other hand, an assignment like "c = a + b" is much more natural
as a reference assignment, for the "everything is a view" philosophy
of the library. Some kind of design compromise needs to be found which
balances the requirements of value assignment and reference assignment.

One way to do this is to make indexing and other similar operations return
a const ndarray, which would make "a(3) = 2" become a compile error. I
believe this adds a small efficiency cost, because "b = a(3)" could no
longer use a move assignment operator, but protecting from this error is vital.

A better syntax for the vassign function would be nice as well. One possibility
would be to introduce an object which collapses to a strided array when
its values are read, and assigns by value when being assigned. This could
work as follows:

    ndarray a = {1, 2, 3, 4, 5};
    ndarray b;

    // Compile error
    a(3) = 2;
    // This assigns to the values in 'a'
    a(3).vals() = 2;
    // These two statements are equivalent. It is likely
    // be desireable to remove the as_strided function so
    // that there is one canonical way of doing this...
    b = (a + 2).vals();
    b = (a + 2).as_strided();



All Data Is Aligned and in Native Byte Order
--------------------------------------------

NumPy supports misaligned data, and data in both big-endian and little-endian
formats. This library should too, but allowing this flexibility everywhere adds
complexity and degrades performance. Instead, data which is not aligned and
in NBO will be exposed in the style of a "generator array". This works nicely
with the expression tree basis for the ndarray, allowing the evaluation code
to assume the data is well-behaved when provided with a strided array, and
enable buffering otherwise.

Output Parameters
-----------------

When output parameters are used, exception safety is not guaranteed.
Since operations can fail part-way through, guaranteeing exception safety
would require making a temporary copy.  In the interests of efficiency,
this is not done. When exception safety is required, the functional-style
operations are recommended.

Label-based Indexing
--------------------

At the data array summit in Austin, a design was hammered to allow for
names of the axes and labels along each axis. There were many use-cases
people wanted for this functionality, some conflicting with each other.

I think there needs to be a big distinction between an ordered mapping,
for instance thinking of the array as a position or time instant with
associated data. For this library, I'd like to restrict the labels
to be strings only, so integer-based and label-based indexing can
live together comfortably.

The axis names and labels should themselves be one-dimensional ndarrays
of UTF8 strings.

Arrays with ndarrays as the Data Type
-------------------------------------

In J, there is an idea of a "boxed" array, which is basically having
the dtype itself consist of arrays. This is a way to support ragged
arrays, and it is natural to extend the indexing operation so that
when more indices are specified than there are dimensions, the
rest of the indices get passed on to index into the elements which
are themselves arrays.

For the dynamic ndarray library, we can treat this mechanism as a
"late binding" idea. Consider an array of strings, where the size
of the string is 0, indicating a "flexible" (this is NumPy's terminology,
perhaps a better name can be found) dtype. Behind the scenes, this
becomes a concrete dtype during each iteration step, so that the strings
themselves may be stored in a packed form along with an array of byte-ranges
to go with it. This would need corresponding API which give a dtype
that could hold all the data in a uniform fashion, which would take the maximum
length of one of the strings.

The way that having ndarray as a dtype should affect

Struct Data Types
-----------------

A data type which is a struct can be considered equivalent to an ndarray
of ndarrays, with the restriction that the subarray shapes and dtypes do
not vary across different elements. Considered in full generality, we can
imagine more ways aspects of the array are static or dynamic, For instance,
a ragged array could be imagined with a uniform dtype, but varying sizes
in the subarray.

Indirect Indexing
-----------------



Boolean Indexing
----------------

Because an ndarray has a specific shape, and the design principle was
chosen that there is no implicit "flat" perspective of an ndarray, an
ndarray "a" boolean indexed with "a>0" cannot produce an ndarray if the
shape of an array must always be fixed. Even in the one-dimensional case,
assigning a negative value to an element of 'a' which was previously
positiv ewould require that the shape of the saved result ndarray change.

To tackle this problem, likely two new facilities need to be added to
the ndarray library.

1. The possibility of an array having a selection mask.
2. The ability for one or more dimensions of the shape to be indeterminate,
   signaled with the value -1.

The selection mask can't be an NA mask like the one introduced recently
into NumPy, but rather one which corresponds to the IGNORE missing value
semantics described in the NumPy missing value NEP.

In NumPy, the boolean index can apply to one, some, or all of the dimensions
of the array. In this library, I propose to restrict that to just one or
all of the dimensions. This mostly works out, but there are some serious
conflicts between facility 1 and facility 2, so they must be separated
into different functions.

To understand why conflating the two mechanisms is problematic, consider
the following C++11 code in a hypothetical C++ REPL (they do exist, for
example cling is one). In each case, the alternative interpretations of
the arrays produce vastly different results.

    :> ndarray a, b, c;
    :> a = arange(5);
    :> b = a((a % 2) == 1);
    :> cout << b << "\n";
    'b' AS SELECTION MASK) ndarray(int32, {IGNORE, 1, IGNORE, 3, IGNORE})?
    'b' AS COMPRESSED)     ndarray(int32, {1, 3})

    :> c = zeros(5, make_dtype<int>());
    :> c.vassign(b);
    'b' AS COMPRESSED)     broadcast error: cannot broadcast shape (2) to (5)
    :> cout << c << "\n";
    'b' AS SELECTION MASK) ndarray(int32, {0, 1, 0, 3, 0})

    :> c = zeros(5, make_dtype<int>());
    :> c({true, true, false, false, false}).vassign(b)
    :> cout << c << "\n";
    'b' AND 'c[...]' AS SELECTION MASK) ndarray(int32, {0, 1, 0, 0, 0})
    'b' AND 'c[...]' AS COMPRESSED)     ndarray(int32, {1, 3, 0, 0, 0})

I propose the selection mask be created by the function ndarray::where,
and the indeterminate dimensions be created by the indexing operator,
which is operator() in C++.  The proposed resolution looks like this:

    :> ndarray a, b, c;
    :> a = arange(5);
    :> b_ix = a((a % 2) == 1);
    :> b_wr = a.where((a % 2) == 1);
    :> cout << b_ix << "\n";
    ndarray(int32, {1, 3})
    :> cout << b_wr << "\n";
    ndarray(int32, {IGNORE, 1, IGNORE, 3, IGNORE})

    :> c = zeros(5, make_dtype<int>());
    :> c.vassign(b_ix);
    broadcast error: cannot broadcast shape (2) to (5)
    :> c.vassign(b_wr):
    :> cout << c << "\n";
    ndarray(int32, {0, 1, 0, 3, 0})

    :> c = zeros(5, make_dtype<int>());
    :> c({true, true, false, false, false}).vassign(b_ix)
    :> cout << c << "\n";
    ndarray(int32, {1, 3, 0, 0, 0})
    :> c = zeros(5, make_dtype<int>());
    :> c.where({true, true, false, false, false}).vassign(b_wr)
    ndarray(int32, {0, 1, 0, 0, 0})

One nice property of this is that for boolean indexing, the programmer
can be sure that each index entry lines up with a particular axis, instead
of having it change if the boolean index object has more than one dimension.

Rejected Boolean Indexing Ideas
-------------------------------

A bad way to handle boolean indexing would be to turn boolean indexing
into an immediate operation like in NumPy. This would create an
inconsistency in the system, and require programmers to parse expressions
in their head to determine which parts of them remain views and which
parts get baked into copies. Another reason this wouldn't be good is that
"a[a>0] + b[a>0]" is forced to evaluate the subexpression "a>0" twice. If
it remains as an expression graph, the expression evaluation code can
notice that it is a common subexpression, and only evaluate it once.

Licensing
---------

Currently, I intend to control the copyright of all the code, not
granting any licenses to anyone else. I'd like to retain the ability
to use it freely as I'd like or open source it in a BSD or GPL license,
so incorporating 3rd party code under non-liberal licenses is unacceptable.
Probably I will incorporate some parts of NumPy, namely ones that I have
contributed, but which will need to be heavily modified to become pleasant
for C++.

Development Log
---------------

Sept 9, 2011

* Initial work on 'dtype' object design/implementation. The dtype is
  an object which once constructed, should never be modified, so it
  only has 'getter' functions, not setters. For more complex dtypes,
  the lifetime is managed by a reference count.

Sept 15, 2011

* Raw casting/assignment functions for converting data. This includes
  "immediate mode" versions for single and multiple elements, and
  "delayed mode" versions which return a function pointer with auxiliary
  data.

Sept 19, 2011

* Added error mode to raw casting/assignment, which can check for
  overflow, truncation of floating point fractional part, or floating
  point inexact conversion.

Sept 20, 2011

* Wrote ndarray.vassign function for scalar inputs. This allows you
  to assign a scalar (including a native C++ scalar) to arrays, with
  a customizable assignment error mode. While I could also make the
  C++ scalar assignment work with ndarray.operator=, I think the ndarray
  assignment operator should be reserved for ndarray reference assignment
  semantics, overloading it would be confusing.

Sept 22, 2011

* Wrote an irange() class, similar to Boost MultiArray's index_range(),
  to support range-based indexing. This is like slice-based indexing in
  Python. Also implemented the indexing in ndarray using operator(). Thought
  about how operator[] might work - Boost MultiArray uses it and can
  do it because whether an index is an integer or a tuple of ranges is
  determined at compile time. In irange() I've allowed it to represent
  an integer index by setting step to zero, something which simplifies the
  implementation for multiple indexing.

Sept 27, 2011

* Over the past few days, have made the arithmetic operators +, -, *, / work. This
  required filling in the iterator mechanism (currently using the object
  raw_ndarray_iter templated on the number of outputs and the number of inputs). 


